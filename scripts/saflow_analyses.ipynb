{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "from mne.io import read_raw_fif\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hytools.vtc_utils import *\n",
    "from hytools.meg_utils import get_ch_pos\n",
    "from autoreject import AutoReject\n",
    "from scipy.io import loadmat, savemat\n",
    "from brainpipe import feature\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_preprocfile('11', 2, os.listdir(PREPROC_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_logfile(subj, bloc, log_files):\n",
    "    ### Find the right logfile for a specific subject and bloc in a list of log_files\n",
    "    # (typically the list of files in the log folder, obtained by \"os.listdir(LOGS_DIR)\")\n",
    "    for file in log_files:\n",
    "        if file[7:9] ==  subj and file[10] == bloc:\n",
    "            break\n",
    "    return file\n",
    "\n",
    "def find_preprocfile(subj, bloc, log_files):\n",
    "    ### Find the right logfile for a specific subject and bloc in a list of log_files\n",
    "    # (typically the list of files in the log folder, obtained by \"os.listdir(LOGS_DIR)\")\n",
    "    for file in log_files:\n",
    "        if file[2:4] ==  subj and file[5] == str(int(bloc)):\n",
    "            break\n",
    "    return file\n",
    "\n",
    "\n",
    "def split_events_by_VTC(INzone, OUTzone, events):\n",
    "    INevents = []\n",
    "    OUTevents = []\n",
    "    counter = 0\n",
    "    for i, event in enumerate(events):\n",
    "        if event[2] == 21:\n",
    "            try:\n",
    "                if events[i+1][2] == 99:\n",
    "                    if counter in INzone:\n",
    "                        INevents.append(event)\n",
    "                    if counter in OUTzone:\n",
    "                        OUTevents.append(event)\n",
    "            except:\n",
    "                print('last event')\n",
    "        elif event[2] == 31:\n",
    "            try:\n",
    "                if events[i+1][2] != 99:\n",
    "                    if counter in INzone:\n",
    "                        INevents.append(event)\n",
    "                    if counter in OUTzone:\n",
    "                        OUTevents.append(event)\n",
    "            except:\n",
    "                print('last event')\n",
    "        counter += 1\n",
    "    INevents = np.asarray(INevents)\n",
    "    OUTevents = np.asarray(OUTevents)\n",
    "    return INevents, OUTevents\n",
    "\n",
    "def split_events_by_VTC_alltrials(INzone, OUTzone, events):\n",
    "    ### keeps all trials, miss included\n",
    "    INevents = []\n",
    "    OUTevents = []\n",
    "    counter = 0\n",
    "    for i, event in enumerate(events):\n",
    "        if event[2] == 21:\n",
    "            try:\n",
    "                if counter in INzone:\n",
    "                    INevents.append(event)\n",
    "                if counter in OUTzone:\n",
    "                    OUTevents.append(event)\n",
    "            except:\n",
    "                print('last event')\n",
    "        elif event[2] == 31:\n",
    "            try:\n",
    "                if counter in INzone:\n",
    "                    INevents.append(event)\n",
    "                if counter in OUTzone:\n",
    "                    OUTevents.append(event)\n",
    "            except:\n",
    "                print('last event')\n",
    "        counter += 1\n",
    "    INevents = np.asarray(INevents)\n",
    "    OUTevents = np.asarray(OUTevents)\n",
    "    return INevents, OUTevents\n",
    "\n",
    "def compute_PSD(epochs, sf, epochs_length, f=None):\n",
    "    if f == None:\n",
    "        f = [ [4, 8], [8, 12], [12, 20], [20, 30], [30, 60], [60, 90], [90, 120] ]\n",
    "    # Choose MEG channels\n",
    "    data = epochs.get_data() # On sort les data de l'objet MNE pour les avoir dans une matrice (un numpy array pour être précis)\n",
    "    data = data.swapaxes(0,1).swapaxes(1,2) # On réarange l'ordre des dimensions pour que ça correspond à ce qui est requis par Brainpipe\n",
    "    objet_PSD = feature.power(sf=int(sf), npts=int(sf*epochs_length), width=int((sf*epochs_length)/2), step=int((sf*epochs_length)/4), f=f, method='hilbert1') # La fonction Brainpipe pour créer un objet de calcul des PSD\n",
    "    data = data[:,0:960,:] # weird trick pour corriger un pb de segmentation jpense\n",
    "    #print(data.shape)\n",
    "    psds = objet_PSD.get(data)[0] # Ici on calcule la PSD !\n",
    "    return psds\n",
    "\n",
    "def array_topoplot(toplot, ch_xy, showtitle=False, titles=None, savefig=False, figpath=None, vmin=-1, vmax=1):\n",
    "    #create fig\n",
    "    fig, ax = plt.subplots(1,len(toplot), figsize=(20,10))\n",
    "    for i, data in enumerate(toplot):\n",
    "        image,_ = mne.viz.plot_topomap(data=data, pos=ch_xy, cmap='magma', vmin=vmin, vmax=vmax, axes=ax[i], show=False)\n",
    "        #option for title\n",
    "        if showtitle == True:\n",
    "            ax[i].set_title(titles[i], fontdict={'fontsize': 20, 'fontweight': 'heavy'})\n",
    "    #add a colorbar at the end of the line (weird trick from https://www.martinos.org/mne/stable/auto_tutorials/stats-sensor-space/plot_stats_spatio_temporal_cluster_sensors.html#sphx-glr-auto-tutorials-stats-sensor-space-plot-stats-spatio-temporal-cluster-sensors-py)\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    divider = make_axes_locatable(ax[-1])\n",
    "    ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    plt.colorbar(image, cax=ax_colorbar)\n",
    "    ax_colorbar.tick_params(labelsize=14)\n",
    "    #save plot if specified\n",
    "    if savefig == True:\n",
    "        plt.savefig(figpath, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = '/storage/Yann/saflow_DATA/'\n",
    "PREPROC_PATH = folderpath + 'saflow_preproc/'\n",
    "LOGS_DIR = \"/home/karim/pCloudDrive/science/saflow/gradCPT/gradCPT_share_Mac_PC/gradCPT_share_Mac_PC/saflow_data/\"\n",
    "IMG_DIR = '/home/karim/pCloudDrive/science/saflow/images/'\n",
    "EPOCHS_DIR = folderpath + 'saflow_epoched/'\n",
    "PSDS_DIR = folderpath + 'saflow_PSD/'\n",
    "\n",
    "FREQS = [ [4, 8], [8, 12], [12, 20], [20, 30], [30, 60], [60, 90], [90, 120] ]\n",
    "FREQS_NAMES = ['theta', 'alpha', 'lobeta', 'hibeta', 'gamma1', 'gamma2', 'gamma3']\n",
    "\n",
    "subj_list = ['04', '05', '06', '07', '08', '09', '10', '11', '12', '13']\n",
    "blocs_list = ['1','2','3', '4', '5', '6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test debug NO ar\n",
    "### Also : Freq VS Rare epochs\n",
    "\n",
    "for subj in subj_list:\n",
    "    for bloc in blocs_list:\n",
    "        ## Open file\n",
    "        preproc_file = find_preprocfile(subj, bloc, os.listdir(PREPROC_PATH))\n",
    "        print(preproc_file)\n",
    "        raw = read_raw_fif(PREPROC_PATH + preproc_file, preload=True)\n",
    "        picks = mne.pick_types(raw.info, meg=True, ref_meg=False, eeg=False, eog=False, stim=False)\n",
    "        \n",
    "        ## segmentation\n",
    "        events = mne.find_events(raw)\n",
    "        event_id = {'Freq': 21, 'Rare': 31}\n",
    "        baseline = (None, 0.0)\n",
    "        reject = {'mag': 4e-12}\n",
    "        tmin, tmax = 0, 0.8\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin,\n",
    "                            tmax=tmax, baseline=baseline, reject=None, picks=picks, preload=True)\n",
    "        psds = compute_PSD(epochs, epochs.info['sfreq'], epochs_length = 0.8)\n",
    "        psds = np.mean(psds, axis=2)\n",
    "        print(psds.shape)\n",
    "        0/0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### OPEN PREPROC FILES AND SEGMENT THEM\n",
    "\n",
    "for subj in subj_list:\n",
    "    for bloc in blocs_list:\n",
    "        ### Find logfile to extract VTC\n",
    "        log_file = find_logfile(subj,bloc,os.listdir(LOGS_DIR))\n",
    "        VTC, INbounds, OUTbounds, INzone, OUTzone = get_VTC_from_file(LOGS_DIR + log_file, lobound=None, hibound=None)\n",
    "        ### Load pre-processed datafile\n",
    "        preproc_file = find_preprocfile(subj, bloc, os.listdir(PREPROC_PATH))\n",
    "        raw = read_raw_fif(PREPROC_PATH + preproc_file, preload=True)\n",
    "        picks = mne.pick_types(raw.info, meg=True, ref_meg=False, eeg=False, eog=False, stim=False)\n",
    "\n",
    "        ### Set some constants for epoching\n",
    "\n",
    "        baseline = (None, 0.0)\n",
    "        reject = {'mag': 4e-12}\n",
    "        tmin, tmax = 0, 0.8\n",
    "\n",
    "        ### Find events, split them by IN/OUT and start epoching\n",
    "        events = mne.find_events(raw, min_duration=2/raw.info['sfreq'])\n",
    "        INevents, OUTevents = split_events_by_VTC(INzone, OUTzone, events)\n",
    "        try:\n",
    "            event_id = {'Freq': 21, 'Rare': 31}\n",
    "            INepochs = mne.Epochs(raw, events=INevents, event_id=event_id, tmin=tmin,\n",
    "                            tmax=tmax, baseline=baseline, reject=None, picks=picks, preload=True)\n",
    "        except:\n",
    "            event_id = {'Freq': 21}\n",
    "            INepochs = mne.Epochs(raw, events=INevents, event_id=event_id, tmin=tmin,\n",
    "                            tmax=tmax, baseline=baseline, reject=None, picks=picks, preload=True)\n",
    "            \n",
    "        try:\n",
    "            event_id = {'Freq': 21, 'Rare': 31}\n",
    "            OUTepochs = mne.Epochs(raw, events=OUTevents, event_id=event_id, tmin=tmin,\n",
    "                            tmax=tmax, baseline=baseline, reject=None, picks=picks, preload=True)\n",
    "        except:\n",
    "            event_id = {'Freq': 21}\n",
    "            OUTepochs = mne.Epochs(raw, events=OUTevents, event_id=event_id, tmin=tmin,\n",
    "                            tmax=tmax, baseline=baseline, reject=None, picks=picks, preload=True)\n",
    "            \n",
    "\n",
    "        ### Autoreject detects, rejects and interpolate artifacted epochs\n",
    "        ar = AutoReject()\n",
    "        INepochs_clean = ar.fit_transform(INepochs)\n",
    "        OUTepochs_clean = ar.fit_transform(OUTepochs)\n",
    "        \n",
    "        INepochs_clean.save(EPOCHS_DIR + 'SA' + subj + '_' + bloc + '_IN_epo.fif.gz')\n",
    "        OUTepochs_clean.save(EPOCHS_DIR + 'SA' + subj + '_' + bloc + '_OUT_epo.fif.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Debug shortest event in find_events\n",
    "\n",
    "\n",
    "subj = '13'\n",
    "bloc = 5\n",
    "preproc_file = find_preprocfile(subj, bloc, os.listdir(PREPROC_PATH))\n",
    "raw = read_raw_fif(PREPROC_PATH + preproc_file, preload=True)\n",
    "picks = mne.pick_types(raw.info, meg=True, ref_meg=False, eeg=False, eog=False, stim=False)\n",
    "\n",
    "### Set some constants for epoching\n",
    "\n",
    "baseline = (None, 0.0)\n",
    "reject = {'mag': 4e-12}\n",
    "tmin, tmax = 0, 0.8\n",
    "\n",
    "### Find events, split them by IN/OUT and start epoching\n",
    "events = mne.find_events(raw, min_duration=2/raw.info['sfreq'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPEN SEGMENTED FILES AND COMPUTE PSDS\n",
    "\n",
    "for subj in subj_list:\n",
    "    for bloc in blocs_list:\n",
    "        for zone in ['IN', 'OUT']:\n",
    "            data = mne.read_epochs(EPOCHS_DIR + 'SA' + subj + '_' + bloc + '_' + zone + '_epo.fif.gz')\n",
    "            psds = compute_PSD(data, data.info['sfreq'], epochs_length = 0.8)\n",
    "            psds = np.mean(psds, axis=2)\n",
    "            for i, freq_name in enumerate(FREQS_NAMES):\n",
    "                PSD_save = psds[i]\n",
    "                savemat(PSDS_DIR + 'SA' + subj + '_' + bloc + '_' + zone + '_' + freq_name + '.mat', {'PSD': PSD_save})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPEN PSDS AND CREATE TOPOPLOTS\n",
    "\n",
    "#### ALL SUBJ TOPOPLOT\n",
    "\n",
    "# create a pdf with psd topoplots\n",
    "ch_file = '/home/karim/pCloudDrive/science/saflow/DATAmeg_gradCPT/20190411/SA04_SAflow-yharel_20190411_02.ds'\n",
    "raw = mne.io.read_raw_ctf(ch_file)\n",
    "ch_xy = get_ch_pos(raw)\n",
    "\n",
    "toplot = []\n",
    "for i, freq_name in enumerate(FREQS_NAMES):\n",
    "    alldata = []\n",
    "    for zone in ['IN', 'OUT']:\n",
    "        zonedata = []\n",
    "        for subj in subj_list:\n",
    "            subjdata = []\n",
    "            for bloc in blocs_list:\n",
    "                mat = loadmat(PSDS_DIR + 'SA' + subj + '_' + bloc + '_' + zone + '_' + freq_name + '.mat')\n",
    "                data = mat['PSD']\n",
    "                if subjdata == []:\n",
    "                    subjdata = data\n",
    "                else:\n",
    "                    subjdata = np.hstack((subjdata, data))\n",
    "            subjdata = np.mean(subjdata, axis=1) # average blocs\n",
    "            zonedata.append(subjdata)\n",
    "        alldata.append(np.asarray(zonedata))\n",
    "    alldata = np.asarray(alldata)\n",
    "    alldata = np.mean(alldata, axis=1) # average subjects\n",
    "    toplot.append((alldata[0] - alldata[1])/alldata[1])\n",
    "array_topoplot(toplot, ch_xy, showtitle=True, titles=FREQS_NAMES, savefig=True, figpath=IMG_DIR + 'IN_vs_OUT_PSD_autoreject_4subj.png', vmin=np.min(np.min(toplot)), vmax=np.max(np.max(toplot)))\n",
    "    #array_topoplot(alldata[1], ch_xy, showtitle=False, titles=None, savefig=False, figpath=None, vmin=-1, vmax=1)\n",
    "\n",
    "    #print(alldata[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPEN PSDS AND CREATE TOPOPLOTS\n",
    "\n",
    "#### INDIVIDUAL SUBJ TOPOPLOT\n",
    "\n",
    "# create a pdf with psd topoplots\n",
    "ch_file = '/home/karim/pCloudDrive/science/saflow/DATAmeg_gradCPT/20190411/SA04_SAflow-yharel_20190411_02.ds'\n",
    "raw = mne.io.read_raw_ctf(ch_file)\n",
    "ch_xy = get_ch_pos(raw)\n",
    "\n",
    "toplot = []\n",
    "for i, freq_name in enumerate(FREQS_NAMES):\n",
    "    alldata = []\n",
    "    for zone in ['IN', 'OUT']:\n",
    "        zonedata = []\n",
    "        for subj in subj_list:\n",
    "            subjdata = []\n",
    "            for bloc in blocs_list:\n",
    "                mat = loadmat(PSDS_DIR + 'SA' + subj + '_' + bloc + '_' + zone + '_' + freq_name + '.mat')\n",
    "                data = mat['PSD']\n",
    "                if subjdata == []:\n",
    "                    subjdata = data\n",
    "                else:\n",
    "                    subjdata = np.hstack((subjdata, data))\n",
    "            subjdata = np.mean(subjdata, axis=1) # average blocs\n",
    "            zonedata.append(subjdata)\n",
    "        alldata.append(np.asarray(zonedata))\n",
    "    #alldata = np.mean(np.asarray(alldata), axis=1) # average subjects\n",
    "    alldata = np.asarray(alldata)\n",
    "    toplot.append((alldata[0] - alldata[1])/alldata[1])\n",
    "toplot = np.asarray(toplot)\n",
    "\n",
    "for i, subj in enumerate(subj_list):\n",
    "    print(subj)\n",
    "    array_topoplot(toplot[:,i,:], ch_xy, showtitle=True, titles=FREQS_NAMES, savefig=True, figpath=IMG_DIR + 'IN_vs_OUT_PSD' + '_SA' + subj + '_NOar.png', vmin=np.min(np.min(toplot)), vmax=np.max(np.max(toplot)))\n",
    "    #array_topoplot(alldata[1], ch_xy, showtitle=False, titles=None, savefig=False, figpath=None, vmin=-1, vmax=1)\n",
    "\n",
    "    #print(alldata[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karim/electrophy/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d5be3c170baf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mblocdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mzone\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'IN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### 1 = IN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m### 0 = OUT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/electrophy/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "### ML single subject classification of IN vs OUT epochs\n",
    "# - single-features\n",
    "# - CV k-fold (maybe 10 ?)\n",
    "# - LDA, RF, kNN ?\n",
    "for subj in subj_list:\n",
    "    all_freq_data = []\n",
    "    for i, freq_name in enumerate(FREQS_NAMES):\n",
    "        zonedata = []\n",
    "        y = np.array([])\n",
    "        for zone in ['IN', 'OUT']:\n",
    "            blocdata = []\n",
    "            for bloc in blocs_list:\n",
    "                mat = loadmat(PSDS_DIR + 'SA' + subj + '_' + bloc + '_' + zone + '_' + freq_name + '.mat')\n",
    "                data = mat['PSD']\n",
    "                if blocdata == []:\n",
    "                    blocdata = data\n",
    "                else:\n",
    "                    blocdata = np.hstack((blocdata, data))\n",
    "            if zone == 'IN':\n",
    "                y = np.vstack((y, np.ones((blocdata.shape[1],1)))) ### 1 = IN\n",
    "            else:\n",
    "                y = np.vstack((y, np.zeros((blocdata.shape[1],1))))### 0 = OUT\n",
    "            print(y.shape)\n",
    "            \n",
    "            if zonedata == []:\n",
    "                zonedata = blocdata\n",
    "            else:\n",
    "                zonedata = np.hstack((zonedata, blocdata))\n",
    "        if all_freq_data == []:\n",
    "            all_freq_data = zonedata\n",
    "        else:\n",
    "            all_freq_data = np.vstack((all_freq_data, zonedata))\n",
    "    print('SA' + subj)\n",
    "    print(all_freq_data.shape)\n",
    "                \n",
    "                    \n",
    "#### Résultat on veut : elec * freq X trials(IN+OUT) = 1890 X N_trials_tot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata_allfreqs = []\n",
    "for i, freq_name in enumerate(FREQS_NAMES):\n",
    "    alldata = []\n",
    "    for zone in ['IN', 'OUT']:\n",
    "        zonedata = []\n",
    "        for subj in subj_list:\n",
    "            subjdata = []\n",
    "            for bloc in blocs_list:\n",
    "                mat = loadmat(PSDS_DIR + 'SA' + subj + '_' + bloc + '_' + zone + '_' + freq_name + '.mat')\n",
    "                data = mat['PSD']\n",
    "                if subjdata == []:\n",
    "                    subjdata = data\n",
    "                else:\n",
    "                    subjdata = np.hstack((subjdata, data))\n",
    "            zonedata.append(subjdata)\n",
    "        alldata.append(zonedata)\n",
    "    alldata_allfreqs.append(alldata) ### First dimension is freq_band, second is IN/OUT, third is subject, fourth is elec X trials matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Objectif : \n",
    "# get one epoched file for freq and rare AND RESP for each subj\n",
    "# PLOT TOPO DE L'AMPLITUDE À ENVIRON 150MS APRES RESP\n",
    "# COMPARER BLOC RESP GAUCHE AVEC BLOC RESP DROIT\n",
    "\n",
    "##### POUR MIKE : implémenter calcul de la VTC sur Python, à partir du fichier de log\n",
    "\n",
    "\n",
    "#for file in file_list:\n",
    "file = file_list[-2]\n",
    "\n",
    "\n",
    "fname = preproc_path + file\n",
    "subj = file[:4]\n",
    "bloc = file[6]\n",
    "\n",
    "raw = read_raw_fif(fname, preload=True)\n",
    "picks = mne.pick_types(raw.info, meg=True, ref_meg=False, eeg=False, eog=False, stim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_files = os.listdir(LOGS_DIR)\n",
    "\n",
    "file = find_logfile(subj,bloc,log_files)\n",
    "VTC, INbounds, OUTbounds, INzone, OUTzone = get_VTC_from_file(LOGS_DIR + file, lobound=0.25, hibound=0.75)\n",
    "\n",
    "INbounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = mne.find_events(raw)\n",
    "event_id = {'Freq': 21, 'Rare': 31}\n",
    "color = {21: 'green', 31: 'yellow'}\n",
    "mne.viz.plot_events(OUTevents, raw.info['sfreq'], raw.first_samp, color=color,\n",
    "                    event_id=event_id);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = []\n",
    "a = np.array(a)\n",
    "b = np.zeros((5,0))\n",
    "c = np.hstack((a,b))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ep = read_raw_fif('/home/karim/DATA/MEG_gradCPT/saflow_epoched/SA04_1_IN.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INevoked_freq = INepochs['Freq'].average()\n",
    "INevoked_rare = INepochs['Rare'].average()\n",
    "OUTevoked_freq = OUTepochs['Freq'].average()\n",
    "OUTevoked_rare = OUTepochs['Rare'].average()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "\n",
    "if a >> 1:\n",
    "    print('lol')\n",
    "else:\n",
    "    print('nana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.arange(0.1, 0.801, 0.1)\n",
    "OUTepochs['Rare'].average().plot_topomap(times=times, time_unit='s', title='Rare');\n",
    "plt.savefig(IMG_DIR + 'evoked_topo_OUTrare.png', dpi=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTepochs['Freq'].average().plot_topomap(times=times, time_unit='s', title='Frequent');\n",
    "plt.savefig(IMG_DIR + 'evoked_topo_OUTfreq.png', dpi=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ar = AutoReject()\n",
    "INepochs_clean = ar.fit_transform(INepochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Faire une fonction qui prend un bloc, va chercher le fichier de log associé, calcule la VTC et les IN/OUT bounds\n",
    "### segmente le fichier et sépare les epochs dans deux fichiers en fonction de la condition de chaque epoch\n",
    "\n",
    "INepochs_clean.average().plot_topomap(times=times, time_unit='s');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "electrophy",
   "language": "python",
   "name": "electrophy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
